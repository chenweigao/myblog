<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>TensorFlow 入门 | weigao chen</title>
    <meta name="description" content="less is more">
    <meta name="generator" content="VuePress 1.4.0">
    <link rel="icon" href="/favicon.png">
  <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    
    <link rel="preload" href="/assets/css/0.styles.5cb4ca26.css" as="style"><link rel="preload" href="/assets/js/app.1b626765.js" as="script"><link rel="preload" href="/assets/js/3.126c0a99.js" as="script"><link rel="preload" href="/assets/js/1.fcd1a95e.js" as="script"><link rel="preload" href="/assets/js/69.5d82ca0d.js" as="script"><link rel="prefetch" href="/assets/js/10.7123ddef.js"><link rel="prefetch" href="/assets/js/11.0cc013fa.js"><link rel="prefetch" href="/assets/js/12.a98a955e.js"><link rel="prefetch" href="/assets/js/13.b05212ac.js"><link rel="prefetch" href="/assets/js/14.dd8aebc1.js"><link rel="prefetch" href="/assets/js/15.5df51032.js"><link rel="prefetch" href="/assets/js/16.6f3a6872.js"><link rel="prefetch" href="/assets/js/17.17df86c8.js"><link rel="prefetch" href="/assets/js/18.e757588a.js"><link rel="prefetch" href="/assets/js/19.340dbbc7.js"><link rel="prefetch" href="/assets/js/20.5b4c5258.js"><link rel="prefetch" href="/assets/js/21.32da6d63.js"><link rel="prefetch" href="/assets/js/22.3ec2ce7b.js"><link rel="prefetch" href="/assets/js/23.6adf0d2c.js"><link rel="prefetch" href="/assets/js/24.9a9de956.js"><link rel="prefetch" href="/assets/js/25.2f8326e7.js"><link rel="prefetch" href="/assets/js/26.4b64b83a.js"><link rel="prefetch" href="/assets/js/27.bd5a9ac4.js"><link rel="prefetch" href="/assets/js/28.a99a4f93.js"><link rel="prefetch" href="/assets/js/29.6cc4f778.js"><link rel="prefetch" href="/assets/js/30.c11b005f.js"><link rel="prefetch" href="/assets/js/31.49c6b152.js"><link rel="prefetch" href="/assets/js/32.59aa7535.js"><link rel="prefetch" href="/assets/js/33.3298e199.js"><link rel="prefetch" href="/assets/js/34.0f27f6f5.js"><link rel="prefetch" href="/assets/js/35.b5b0d2a5.js"><link rel="prefetch" href="/assets/js/36.9fcbbfe6.js"><link rel="prefetch" href="/assets/js/37.46b9d464.js"><link rel="prefetch" href="/assets/js/38.9c0f7250.js"><link rel="prefetch" href="/assets/js/39.12e5f944.js"><link rel="prefetch" href="/assets/js/4.c710bbb0.js"><link rel="prefetch" href="/assets/js/40.be213f7d.js"><link rel="prefetch" href="/assets/js/41.3031e55a.js"><link rel="prefetch" href="/assets/js/42.67c288b0.js"><link rel="prefetch" href="/assets/js/43.222739e3.js"><link rel="prefetch" href="/assets/js/44.39970a7c.js"><link rel="prefetch" href="/assets/js/45.2d4e88ef.js"><link rel="prefetch" href="/assets/js/46.3e9a4581.js"><link rel="prefetch" href="/assets/js/47.1d6cc4a8.js"><link rel="prefetch" href="/assets/js/48.e9117b4a.js"><link rel="prefetch" href="/assets/js/49.f83bbea3.js"><link rel="prefetch" href="/assets/js/5.c9914649.js"><link rel="prefetch" href="/assets/js/50.901891bd.js"><link rel="prefetch" href="/assets/js/51.84af2873.js"><link rel="prefetch" href="/assets/js/52.f1be7b19.js"><link rel="prefetch" href="/assets/js/53.990529e5.js"><link rel="prefetch" href="/assets/js/54.b1816298.js"><link rel="prefetch" href="/assets/js/55.d3149d30.js"><link rel="prefetch" href="/assets/js/56.c13bc276.js"><link rel="prefetch" href="/assets/js/57.11bda43f.js"><link rel="prefetch" href="/assets/js/58.a2e81591.js"><link rel="prefetch" href="/assets/js/59.0313dc7c.js"><link rel="prefetch" href="/assets/js/6.d932b55a.js"><link rel="prefetch" href="/assets/js/60.52fbdd03.js"><link rel="prefetch" href="/assets/js/61.0f261514.js"><link rel="prefetch" href="/assets/js/62.c3a6ca9c.js"><link rel="prefetch" href="/assets/js/63.eba4bd4b.js"><link rel="prefetch" href="/assets/js/64.8287bfb8.js"><link rel="prefetch" href="/assets/js/65.f6ae2259.js"><link rel="prefetch" href="/assets/js/66.33daf86f.js"><link rel="prefetch" href="/assets/js/67.956368ca.js"><link rel="prefetch" href="/assets/js/68.0bdde83a.js"><link rel="prefetch" href="/assets/js/7.4cca0799.js"><link rel="prefetch" href="/assets/js/70.98d50100.js"><link rel="prefetch" href="/assets/js/71.ae29c8b6.js"><link rel="prefetch" href="/assets/js/72.32873ea9.js"><link rel="prefetch" href="/assets/js/73.7c5852ab.js"><link rel="prefetch" href="/assets/js/74.bb76b6fd.js"><link rel="prefetch" href="/assets/js/75.0aaba620.js"><link rel="prefetch" href="/assets/js/76.e3f10d34.js"><link rel="prefetch" href="/assets/js/77.d2c2a673.js"><link rel="prefetch" href="/assets/js/78.1e19221f.js"><link rel="prefetch" href="/assets/js/79.16e993f2.js"><link rel="prefetch" href="/assets/js/8.9e053d17.js"><link rel="prefetch" href="/assets/js/80.7c209e1e.js"><link rel="prefetch" href="/assets/js/81.33b700cc.js"><link rel="prefetch" href="/assets/js/82.c3257197.js"><link rel="prefetch" href="/assets/js/83.da993284.js"><link rel="prefetch" href="/assets/js/9.36f076e6.js">
    <link rel="stylesheet" href="/assets/css/0.styles.5cb4ca26.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container" data-v-146b4d24><div data-v-146b4d24><div id="loader-wrapper" class="loading-wrapper" data-v-d48f4d20 data-v-146b4d24 data-v-146b4d24><div class="loader-main" data-v-d48f4d20><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div></div> <!----> <!----></div> <div class="password-shadow password-wrapper-out" style="display:none;" data-v-64685f0e data-v-146b4d24 data-v-146b4d24><h3 class="title" style="display:none;" data-v-64685f0e data-v-64685f0e>weigao chen</h3> <!----> <label id="box" class="inputBox" style="display:none;" data-v-64685f0e data-v-64685f0e><input type="password" value="" data-v-64685f0e> <span data-v-64685f0e>Konck! Knock!</span> <button data-v-64685f0e>OK</button></label> <div class="footer" style="display:none;" data-v-64685f0e data-v-64685f0e><span data-v-64685f0e><i class="iconfont reco-theme" data-v-64685f0e></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-64685f0e>vuePress-theme-reco</a></span> <span data-v-64685f0e><i class="iconfont reco-copyright" data-v-64685f0e></i> <a data-v-64685f0e><span data-v-64685f0e>weigaochen</span>
            
          <span data-v-64685f0e>2017 - </span>
          2020
        </a></span></div></div> <div class="hide" data-v-146b4d24><header class="navbar" data-v-146b4d24><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/logo.png" alt="weigao chen" class="logo"> <span class="site-name">weigao chen</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/Algorithm/" class="nav-link"><i class="iconfont undefined"></i>
  Algorithm
</a></li><li class="dropdown-item"><!----> <a href="/categories/Database/" class="nav-link"><i class="iconfont undefined"></i>
  Database
</a></li><li class="dropdown-item"><!----> <a href="/categories/Frameworks/" class="nav-link"><i class="iconfont undefined"></i>
  Frameworks
</a></li><li class="dropdown-item"><!----> <a href="/categories/Python/" class="nav-link"><i class="iconfont undefined"></i>
  Python
</a></li><li class="dropdown-item"><!----> <a href="/categories/Frontend/" class="nav-link"><i class="iconfont undefined"></i>
  Frontend
</a></li><li class="dropdown-item"><!----> <a href="/categories/Grammar/" class="nav-link"><i class="iconfont undefined"></i>
  Grammar
</a></li><li class="dropdown-item"><!----> <a href="/categories/Networks/" class="nav-link"><i class="iconfont undefined"></i>
  Networks
</a></li><li class="dropdown-item"><!----> <a href="/categories/Others/" class="nav-link"><i class="iconfont undefined"></i>
  Others
</a></li><li class="dropdown-item"><!----> <a href="/categories/Projects/" class="nav-link"><i class="iconfont undefined"></i>
  Projects
</a></li><li class="dropdown-item"><!----> <a href="/categories/Research/" class="nav-link"><i class="iconfont undefined"></i>
  Research
</a></li><li class="dropdown-item"><!----> <a href="/categories/Server/" class="nav-link"><i class="iconfont undefined"></i>
  Server
</a></li><li class="dropdown-item"><!----> <a href="/categories/Cloud/" class="nav-link"><i class="iconfont undefined"></i>
  Cloud
</a></li><li class="dropdown-item"><!----> <a href="/categories/Linux/" class="nav-link"><i class="iconfont undefined"></i>
  Linux
</a></li><li class="dropdown-item"><!----> <a href="/categories/Tools/" class="nav-link"><i class="iconfont undefined"></i>
  Tools
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="mailto:mail@weigao.cc" class="nav-link external"><i class="iconfont reco-mail"></i>
  Email
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li><li class="dropdown-item"><!----> <a href="https://github.com/chenweigao" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-146b4d24></div> <aside class="sidebar" data-v-146b4d24><div class="personal-info-wrapper" data-v-b038cec6><img src="/avatar.png" alt="author-avatar" class="personal-img" data-v-b038cec6> <h3 class="name" data-v-b038cec6>
    weigaochen
  </h3> <div class="num" data-v-b038cec6><div data-v-b038cec6><h3 data-v-b038cec6>62</h3> <h6 data-v-b038cec6>文章</h6></div> <div data-v-b038cec6><h3 data-v-b038cec6>49</h3> <h6 data-v-b038cec6>标签</h6></div></div> <hr data-v-b038cec6></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/Algorithm/" class="nav-link"><i class="iconfont undefined"></i>
  Algorithm
</a></li><li class="dropdown-item"><!----> <a href="/categories/Database/" class="nav-link"><i class="iconfont undefined"></i>
  Database
</a></li><li class="dropdown-item"><!----> <a href="/categories/Frameworks/" class="nav-link"><i class="iconfont undefined"></i>
  Frameworks
</a></li><li class="dropdown-item"><!----> <a href="/categories/Python/" class="nav-link"><i class="iconfont undefined"></i>
  Python
</a></li><li class="dropdown-item"><!----> <a href="/categories/Frontend/" class="nav-link"><i class="iconfont undefined"></i>
  Frontend
</a></li><li class="dropdown-item"><!----> <a href="/categories/Grammar/" class="nav-link"><i class="iconfont undefined"></i>
  Grammar
</a></li><li class="dropdown-item"><!----> <a href="/categories/Networks/" class="nav-link"><i class="iconfont undefined"></i>
  Networks
</a></li><li class="dropdown-item"><!----> <a href="/categories/Others/" class="nav-link"><i class="iconfont undefined"></i>
  Others
</a></li><li class="dropdown-item"><!----> <a href="/categories/Projects/" class="nav-link"><i class="iconfont undefined"></i>
  Projects
</a></li><li class="dropdown-item"><!----> <a href="/categories/Research/" class="nav-link"><i class="iconfont undefined"></i>
  Research
</a></li><li class="dropdown-item"><!----> <a href="/categories/Server/" class="nav-link"><i class="iconfont undefined"></i>
  Server
</a></li><li class="dropdown-item"><!----> <a href="/categories/Cloud/" class="nav-link"><i class="iconfont undefined"></i>
  Cloud
</a></li><li class="dropdown-item"><!----> <a href="/categories/Linux/" class="nav-link"><i class="iconfont undefined"></i>
  Linux
</a></li><li class="dropdown-item"><!----> <a href="/categories/Tools/" class="nav-link"><i class="iconfont undefined"></i>
  Tools
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="mailto:mail@weigao.cc" class="nav-link external"><i class="iconfont reco-mail"></i>
  Email
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li><li class="dropdown-item"><!----> <a href="https://github.com/chenweigao" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></li></ul></div></div> <!----></nav>  <ul class="sidebar-links"><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>TensorFlow 入门</span> <!----></p> <!----></section></li></ul> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-64685f0e data-v-146b4d24><h3 class="title" style="display:none;" data-v-64685f0e data-v-64685f0e>TensorFlow 入门</h3> <!----> <label id="box" class="inputBox" style="display:none;" data-v-64685f0e data-v-64685f0e><input type="password" value="" data-v-64685f0e> <span data-v-64685f0e>Konck! Knock!</span> <button data-v-64685f0e>OK</button></label> <div class="footer" style="display:none;" data-v-64685f0e data-v-64685f0e><span data-v-64685f0e><i class="iconfont reco-theme" data-v-64685f0e></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-64685f0e>vuePress-theme-reco</a></span> <span data-v-64685f0e><i class="iconfont reco-copyright" data-v-64685f0e></i> <a data-v-64685f0e><span data-v-64685f0e>weigaochen</span>
            
          <span data-v-64685f0e>2017 - </span>
          2020
        </a></span></div></div> <div data-v-146b4d24><main class="page"><div class="page-title" style="display:none;"><h1>TensorFlow 入门</h1> <hr> <div data-v-484a899e><i class="iconfont reco-account" data-v-484a899e><span data-v-484a899e>weigaochen</span></i> <i class="iconfont reco-date" data-v-484a899e><span data-v-484a899e>2017-12-10</span></i> <!----> <i class="iconfont reco-tag tags" data-v-484a899e><span class="tag-item" data-v-484a899e>
      paper
    </span><span class="tag-item" data-v-484a899e>
      CV
    </span><span class="tag-item" data-v-484a899e>
      deeplearning
    </span></i></div></div> <div class="theme-reco-content content__default" style="display:none;"><p>Tensorflow中一些简单但是容易忘记的：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
a <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span> <span class="token comment">#用来表示矩阵的乘法操作</span>

weight <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 

bias <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#偏置项</span>
</code></pre></div><p>tf.Variable为初始化变量的操作，tf.random_normal指定了一个2*3的矩阵，元素均值为0，标准差为2，并且，符合正态分布，其他的可以参考tensorflow随机数生成函数</p> <p>接下来这段代码实现神经网络的<strong>前向传播</strong>过程</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
w2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev <span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span><span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

a <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>w2<span class="token punctuation">)</span>

sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>

sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">.</span>initializer<span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w2<span class="token punctuation">.</span>initializer<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p><strong>关于placeholder</strong>
一般而言，我们需要使用常量：</p> <p><code>x = tf.constant([[0.7,0.9]])</code></p> <p>但是这样明显加大了tensorflow的计算量，所以引入了placeholder，这时候我们只需要将数据传入计算图，下面是一个例子：</p> <p><code>x = tf.placeholder(tf.float32,shape = (1,2), name = &quot;input&quot;)</code></p> <p>其中的shape属性可以不指定，因为数据的维度信息可以根据提供的数据推导得出，但是确定的维度的给出可以降低出错的概论。下面的代码为placeholder实现前向传播算法：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
w2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name <span class="token operator">=</span> <span class="token string">&quot;input&quot;</span><span class="token punctuation">)</span>
a <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>w2<span class="token punctuation">)</span>

sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>
init_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_op<span class="token punctuation">)</span>

<span class="token comment"># print(sess.run(y))</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>y<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span><span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>需要注意的是被注释的那行代码<code># print(sess.run(y))</code>，如果运行的话，解释器会报告一个错误，这是因为我们需要提供一个feed_dict来指定x的取值。
如果我们需要多个样例的传播结果，只需要：</p> <p><code>x = tf.placeholder(tf.float32,shape=(3,2),name=&quot;input&quot;)</code> #3个</p> <p>然后给出三组数据即可：</p> <p><code>sess.run(y,feed_dict={x:[[0.7,0.9],[0.1,0.4],[0.5,0.8]]})</code></p> <p>而后我们定义loss函数来刻画预测值和真实值之间的差距，然后通过反向传播算法来调整神经网络的取值从而缩小差距</p> <div class="language-python extra-class"><pre class="language-python"><code>cross_entropy <span class="token operator">=</span> <span class="token operator">-</span>tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>y_ <span class="token operator">*</span> tf<span class="token punctuation">.</span>log<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>clip_by_value<span class="token punctuation">(</span>y<span class="token punctuation">,</span><span class="token number">1e</span><span class="token operator">-</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">)</span>
</code></pre></div><p>cross_entropy定义了真实值和预测值之间的<em>交叉熵</em>。
具体而言，交叉熵刚开始的意义是刻画了两个概论分布之间的距离，是分类问题中使用比较广的一种损失函数。在代码中的含义就是y`表示正确结果，y代表预测结果,并且将张量中的数值限制在1E-10~1.0之间，以避免一些运算错误
如果与softmax一起使用的话，tensorflow对这两个功能进行了统一封装，调用</p> <p><code>cross_entropy=tf.nn.softmax_cross_entropy_with_logits(y,y_)</code></p> <p>下面是训练过程开始的代码：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    init_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_op<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w2<span class="token punctuation">)</span><span class="token punctuation">)</span>

    STEPS <span class="token operator">=</span> <span class="token number">5000</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>STEPS<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start <span class="token operator">=</span> <span class="token punctuation">(</span>i <span class="token operator">*</span> batch_size<span class="token punctuation">)</span> <span class="token operator">%</span> dataset_size
        end <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>start <span class="token operator">+</span> batch_size<span class="token punctuation">,</span> dataset_size<span class="token punctuation">)</span>

        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span> X<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">,</span> y_<span class="token punctuation">:</span> Y<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            total_cross_entropy <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span>X<span class="token punctuation">,</span>y_<span class="token punctuation">:</span>Y<span class="token punctuation">}</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;After %d training steps,cross entropy is %g&quot;</span><span class="token operator">%</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>total_cross_entropy<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w2<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>训练循环了5000次，可以观察到交叉熵的值是越来越小的，这表明预测的结果和真实值的差距越来越小
最后的两行输出表示训练之后神经网络的值</p> <p>**总结一下，训练神经网络的过程可以分为以下三个步骤：</p> <ul><li>定义网络的结构和前向传播的输出</li> <li>定义损失函数和选择反向传播优化的算法</li> <li>生成会话并且在训练数据上反复运行反向传播优化算法**</li></ul> <p>有的时候需要自定义损失函数：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf 
<span class="token keyword">from</span> numpy<span class="token punctuation">.</span>random <span class="token keyword">import</span> RandomState

batch_size <span class="token operator">=</span> <span class="token number">8</span>

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name <span class="token operator">=</span> <span class="token string">'x-input'</span><span class="token punctuation">)</span>
y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name <span class="token operator">=</span> <span class="token string">'y-input'</span><span class="token punctuation">)</span>

w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span>seed <span class="token operator">=</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span>

loss_less <span class="token operator">=</span> <span class="token number">10</span>
loss_more <span class="token operator">=</span> <span class="token number">1</span>
loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>where<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>greater<span class="token punctuation">(</span>y<span class="token punctuation">,</span>y_<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>y<span class="token operator">-</span>y_<span class="token punctuation">)</span><span class="token operator">*</span>loss_more<span class="token punctuation">,</span><span class="token punctuation">(</span>y_<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token operator">*</span>loss_less<span class="token punctuation">)</span><span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

rdm <span class="token operator">=</span> RandomState<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
dataset_size <span class="token operator">=</span> <span class="token number">128</span>
X <span class="token operator">=</span> rdm<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>dataset_size<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>x1<span class="token operator">+</span>x2<span class="token operator">+</span>rdm<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">10.0</span><span class="token operator">-</span><span class="token number">0.05</span><span class="token punctuation">]</span> <span class="token keyword">for</span> <span class="token punctuation">(</span>x1<span class="token punctuation">,</span>x2<span class="token punctuation">)</span> <span class="token keyword">in</span> X<span class="token punctuation">]</span>

<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    init_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_op<span class="token punctuation">)</span>
    Steps <span class="token operator">=</span> <span class="token number">5000</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>Steps<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start <span class="token operator">=</span> <span class="token punctuation">(</span>i<span class="token operator">*</span>batch_size<span class="token punctuation">)</span> <span class="token operator">%</span> dataset_size
        end <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>start<span class="token operator">+</span>batch_size<span class="token punctuation">,</span>dataset_size<span class="token punctuation">)</span>
        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span>X<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span> <span class="token punctuation">,</span> y_<span class="token punctuation">:</span>Y<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre></div><p>以上自定义了一个损失函数，实际值和预测值之间存在的差值分配不用的系数，我们也可以使用均方误差(MSE)：</p> <p><code>loss = tf.reduce_mean(tf.square(y_-y))</code></p> <p>通过比较输出的结果可以看出，不同的损失函数会对模型产生重要影响。</p> <p>在优化参数的时候，梯度下降法是最常用的神经网络优化算法，具体而言，对于一个优化算法而言，第一步随机产生一个参数的初始值，然后通过梯度和学习率来更新参数的取值。
梯度下降算法的两个缺陷：第一是可能得到局部最优的结果，第二是计算时间太长，因为要计算所有训练数据的损失函数是非常耗时间的，所以就可以使用随机梯度下降算法，具体而言，就是在每一轮的迭代中，随机优化某一条训练数据上的损失函数，但是随机梯度下降法有的时候甚至无法达到局部最优，所以一般采用<strong>每次计算一小部分训练数据的损失函数</strong>的方法，这一小部分数据称为一个batch。</p> <p>对于learning_rate，常用的是指数衰减法</p> <div class="language-python extra-class"><pre class="language-python"><code>global_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
learning_rate <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>exponential_decay<span class="token punctuation">(</span><span class="token number">0.001</span><span class="token punctuation">,</span>global_step<span class="token punctuation">,</span> <span class="token number">100</span> <span class="token punctuation">,</span> <span class="token number">0.96</span> <span class="token punctuation">,</span>staircase<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
</code></pre></div><p>dacay_steps代表了完整的使用一遍训练数据所需要的迭代轮数（总训练样本数除以每一个batch的训练样本数），staircase的值为True时，global_step/decay_steps会被转化成整数。上面各个参数的含义是每训练100轮后学习率乘以0.96。经验有助于设置好学习率、衰减系数和衰减速度。</p> <div class="language-python extra-class"><pre class="language-python"><code>batch_size <span class="token operator">=</span> n

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>dtype<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span>
y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>dtype<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span>

loss <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

<span class="token keyword">with</span> <span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">:</span>
	<span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>STEPS<span class="token punctuation">)</span><span class="token punctuation">:</span>
		current_X<span class="token punctuation">,</span>surrent_Y <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
		sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step<span class="token punctuation">,</span>feed_sict <span class="token operator">=</span> <span class="token punctuation">{</span>x<span class="token punctuation">:</span>current_X<span class="token punctuation">,</span>y_<span class="token punctuation">:</span>current_Y<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre></div><p>以上代码概括了一般神经网络的训练大致遵循的过程。</p></div> <footer class="page-edit" style="display:none;"><!----> <div class="last-updated"><span class="prefix">Last Updated: </span> <span class="time">2020-3-26 16:20:57</span></div></footer> <!----></main> <!----> <div style="display:none;" data-v-146b4d24 data-v-146b4d24><div class="comments-wrapper" data-v-146b4d24><!----></div></div></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-44bd5a18 data-v-44bd5a18><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-44bd5a18><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-44bd5a18></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-44bd5a18></path></svg></div></div></div>
    <script src="/assets/js/app.1b626765.js" defer></script><script src="/assets/js/3.126c0a99.js" defer></script><script src="/assets/js/1.fcd1a95e.js" defer></script><script src="/assets/js/69.5d82ca0d.js" defer></script>
  </body>
</html>
