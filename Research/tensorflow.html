<!DOCTYPE html>
<html lang="zh-CN">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>TensorFlow 入门 | Chener丶</title>
    <meta name="generator" content="VuePress 1.8.2">
    <link rel="icon" href="/favicon.png">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.slim.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.2/jquery.fancybox.min.js"></script>
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.2/jquery.fancybox.min.css">
    <meta name="description" content="weigao.cc">
    <meta name="viewport" content="width=device-width,initial-scale=1,user-scalable=no">
    
    <link rel="preload" href="/assets/css/0.styles.71994f2f.css" as="style"><link rel="preload" href="/assets/js/app.ff413545.js" as="script"><link rel="preload" href="/assets/js/3.a9798fbe.js" as="script"><link rel="preload" href="/assets/js/1.76b01c69.js" as="script"><link rel="preload" href="/assets/js/89.8d98fea8.js" as="script"><link rel="preload" href="/assets/js/9.0cdfd736.js" as="script"><link rel="prefetch" href="/assets/js/10.0a183579.js"><link rel="prefetch" href="/assets/js/11.a03ef169.js"><link rel="prefetch" href="/assets/js/12.f26a7d7a.js"><link rel="prefetch" href="/assets/js/13.d3b95d41.js"><link rel="prefetch" href="/assets/js/14.4ea22ee2.js"><link rel="prefetch" href="/assets/js/15.8fb23eac.js"><link rel="prefetch" href="/assets/js/16.cf8de121.js"><link rel="prefetch" href="/assets/js/17.c225ab11.js"><link rel="prefetch" href="/assets/js/18.11e29de6.js"><link rel="prefetch" href="/assets/js/19.8a55d76b.js"><link rel="prefetch" href="/assets/js/20.e4a0d4f9.js"><link rel="prefetch" href="/assets/js/21.bfa3ed5f.js"><link rel="prefetch" href="/assets/js/22.881078d3.js"><link rel="prefetch" href="/assets/js/23.b7063063.js"><link rel="prefetch" href="/assets/js/24.21afc6da.js"><link rel="prefetch" href="/assets/js/25.863e4060.js"><link rel="prefetch" href="/assets/js/26.3b9440f2.js"><link rel="prefetch" href="/assets/js/27.02956fa3.js"><link rel="prefetch" href="/assets/js/28.d326838a.js"><link rel="prefetch" href="/assets/js/29.f4789005.js"><link rel="prefetch" href="/assets/js/30.178fccd3.js"><link rel="prefetch" href="/assets/js/31.5e994fb5.js"><link rel="prefetch" href="/assets/js/32.69ace0dc.js"><link rel="prefetch" href="/assets/js/33.e80e519b.js"><link rel="prefetch" href="/assets/js/34.11406db4.js"><link rel="prefetch" href="/assets/js/35.70105e9a.js"><link rel="prefetch" href="/assets/js/36.7e1aa7a6.js"><link rel="prefetch" href="/assets/js/37.8f4fbae0.js"><link rel="prefetch" href="/assets/js/38.c0b3f0ad.js"><link rel="prefetch" href="/assets/js/39.2910de4d.js"><link rel="prefetch" href="/assets/js/4.d53fc5cb.js"><link rel="prefetch" href="/assets/js/40.96057ad6.js"><link rel="prefetch" href="/assets/js/41.7b92e916.js"><link rel="prefetch" href="/assets/js/42.cc499b8b.js"><link rel="prefetch" href="/assets/js/43.29ddf432.js"><link rel="prefetch" href="/assets/js/44.49411b58.js"><link rel="prefetch" href="/assets/js/45.f28f6522.js"><link rel="prefetch" href="/assets/js/46.e9ddcabc.js"><link rel="prefetch" href="/assets/js/47.282e2a7d.js"><link rel="prefetch" href="/assets/js/48.519e3a8e.js"><link rel="prefetch" href="/assets/js/49.242aa181.js"><link rel="prefetch" href="/assets/js/5.7aedaec4.js"><link rel="prefetch" href="/assets/js/50.1317de68.js"><link rel="prefetch" href="/assets/js/51.c34b4a17.js"><link rel="prefetch" href="/assets/js/52.3b7dd990.js"><link rel="prefetch" href="/assets/js/53.ed1e8e58.js"><link rel="prefetch" href="/assets/js/54.e8e04427.js"><link rel="prefetch" href="/assets/js/55.91b961cc.js"><link rel="prefetch" href="/assets/js/56.1f4b4373.js"><link rel="prefetch" href="/assets/js/57.24930676.js"><link rel="prefetch" href="/assets/js/58.0c07ef31.js"><link rel="prefetch" href="/assets/js/59.97c8f9ce.js"><link rel="prefetch" href="/assets/js/6.56dd9870.js"><link rel="prefetch" href="/assets/js/60.f576cac3.js"><link rel="prefetch" href="/assets/js/61.6e4fb3ef.js"><link rel="prefetch" href="/assets/js/62.500fedcd.js"><link rel="prefetch" href="/assets/js/63.7f31b89f.js"><link rel="prefetch" href="/assets/js/64.31554884.js"><link rel="prefetch" href="/assets/js/65.18b55458.js"><link rel="prefetch" href="/assets/js/66.4afdc430.js"><link rel="prefetch" href="/assets/js/67.61362a31.js"><link rel="prefetch" href="/assets/js/68.65a12531.js"><link rel="prefetch" href="/assets/js/69.541c8690.js"><link rel="prefetch" href="/assets/js/7.799fb789.js"><link rel="prefetch" href="/assets/js/70.ed1a8749.js"><link rel="prefetch" href="/assets/js/71.201c3cf0.js"><link rel="prefetch" href="/assets/js/72.e314ebf4.js"><link rel="prefetch" href="/assets/js/73.83a7e061.js"><link rel="prefetch" href="/assets/js/74.b3e1c780.js"><link rel="prefetch" href="/assets/js/75.c79f5b1a.js"><link rel="prefetch" href="/assets/js/76.1a92c366.js"><link rel="prefetch" href="/assets/js/77.7c7a602c.js"><link rel="prefetch" href="/assets/js/78.dd3c1e50.js"><link rel="prefetch" href="/assets/js/79.ff0da6f3.js"><link rel="prefetch" href="/assets/js/8.d10012db.js"><link rel="prefetch" href="/assets/js/80.4fdb3bf5.js"><link rel="prefetch" href="/assets/js/81.e8c76ed8.js"><link rel="prefetch" href="/assets/js/82.bacff8ea.js"><link rel="prefetch" href="/assets/js/83.355ad832.js"><link rel="prefetch" href="/assets/js/84.7aaaca56.js"><link rel="prefetch" href="/assets/js/85.5cfb875b.js"><link rel="prefetch" href="/assets/js/86.03aa4eeb.js"><link rel="prefetch" href="/assets/js/87.eacb2bae.js"><link rel="prefetch" href="/assets/js/88.eb7da425.js"><link rel="prefetch" href="/assets/js/90.912b6c51.js"><link rel="prefetch" href="/assets/js/91.47042b16.js"><link rel="prefetch" href="/assets/js/92.2bab0beb.js"><link rel="prefetch" href="/assets/js/93.fe1eb37c.js"><link rel="prefetch" href="/assets/js/94.ddb8318d.js"><link rel="prefetch" href="/assets/js/95.026e939f.js"><link rel="prefetch" href="/assets/js/96.7f41b6ed.js">
    <link rel="stylesheet" href="/assets/css/0.styles.71994f2f.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container no-sidebar" data-v-1156296a><div data-v-1156296a><div id="loader-wrapper" class="loading-wrapper" data-v-d48f4d20 data-v-1156296a data-v-1156296a><div class="loader-main" data-v-d48f4d20><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div><div data-v-d48f4d20></div></div> <!----> <!----></div> <div class="password-shadow password-wrapper-out" style="display:none;" data-v-4e82dffc data-v-1156296a data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>Chener丶</h3> <p class="description" data-v-4e82dffc data-v-4e82dffc>weigao.cc</p> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>weigaochen</span>
            
          <span data-v-4e82dffc>2017 - </span>
          2022
        </a></span></div></div> <div class="hide" data-v-1156296a><header class="navbar" data-v-1156296a><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/" class="home-link router-link-active"><img src="/logo.png" alt="Chener丶" class="logo"> <span class="site-name">Chener丶</span></a> <div class="links"><div class="color-picker"><a class="color-button"><i class="iconfont reco-color"></i></a> <div class="color-picker-menu" style="display:none;"><div class="mode-options"><h4 class="title">Choose mode</h4> <ul class="color-mode-options"><li class="dark">dark</li><li class="auto active">auto</li><li class="light">light</li></ul></div></div></div> <div class="search-box"><i class="iconfont reco-search"></i> <input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/Algorithm/" class="nav-link"><i class="undefined"></i>
  Algorithm
</a></li><li class="dropdown-item"><!----> <a href="/categories/Server/" class="nav-link"><i class="undefined"></i>
  Server
</a></li><li class="dropdown-item"><!----> <a href="/categories/Cloud/" class="nav-link"><i class="undefined"></i>
  Cloud
</a></li><li class="dropdown-item"><!----> <a href="/categories/Linux/" class="nav-link"><i class="undefined"></i>
  Linux
</a></li><li class="dropdown-item"><!----> <a href="/categories/Database/" class="nav-link"><i class="undefined"></i>
  Database
</a></li><li class="dropdown-item"><!----> <a href="/categories/Frameworks/" class="nav-link"><i class="undefined"></i>
  Frameworks
</a></li><li class="dropdown-item"><!----> <a href="/categories/Python/" class="nav-link"><i class="undefined"></i>
  Python
</a></li><li class="dropdown-item"><!----> <a href="/categories/Frontend/" class="nav-link"><i class="undefined"></i>
  Frontend
</a></li><li class="dropdown-item"><!----> <a href="/categories/Grammar/" class="nav-link"><i class="undefined"></i>
  Grammar
</a></li><li class="dropdown-item"><!----> <a href="/categories/Networks/" class="nav-link"><i class="undefined"></i>
  Networks
</a></li><li class="dropdown-item"><!----> <a href="/categories/Others/" class="nav-link"><i class="undefined"></i>
  Others
</a></li><li class="dropdown-item"><!----> <a href="/categories/Projects/" class="nav-link"><i class="undefined"></i>
  Projects
</a></li><li class="dropdown-item"><!----> <a href="/categories/Research/" class="nav-link"><i class="undefined"></i>
  Research
</a></li><li class="dropdown-item"><!----> <a href="/categories/Tools/" class="nav-link"><i class="undefined"></i>
  Tools
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="mailto:mail@weigao.cc" class="nav-link external"><i class="iconfont reco-mail"></i>
  Email
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://github.com/chenweigao" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav></div></header> <div class="sidebar-mask" data-v-1156296a></div> <aside class="sidebar" data-v-1156296a><div class="personal-info-wrapper" data-v-828910c6 data-v-1156296a><img src="/avatar.png" alt="author-avatar" class="personal-img" data-v-828910c6> <h3 class="name" data-v-828910c6>
    weigaochen
  </h3> <div class="num" data-v-828910c6><div data-v-828910c6><h3 data-v-828910c6>79</h3> <h6 data-v-828910c6>文章</h6></div> <div data-v-828910c6><h3 data-v-828910c6>58</h3> <h6 data-v-828910c6>标签</h6></div></div> <ul class="social-links" data-v-828910c6></ul> <hr data-v-828910c6></div> <nav class="nav-links"><div class="nav-item"><a href="/" class="nav-link"><i class="iconfont reco-home"></i>
  Home
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-category"></i>
      Category
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="/categories/Algorithm/" class="nav-link"><i class="undefined"></i>
  Algorithm
</a></li><li class="dropdown-item"><!----> <a href="/categories/Server/" class="nav-link"><i class="undefined"></i>
  Server
</a></li><li class="dropdown-item"><!----> <a href="/categories/Cloud/" class="nav-link"><i class="undefined"></i>
  Cloud
</a></li><li class="dropdown-item"><!----> <a href="/categories/Linux/" class="nav-link"><i class="undefined"></i>
  Linux
</a></li><li class="dropdown-item"><!----> <a href="/categories/Database/" class="nav-link"><i class="undefined"></i>
  Database
</a></li><li class="dropdown-item"><!----> <a href="/categories/Frameworks/" class="nav-link"><i class="undefined"></i>
  Frameworks
</a></li><li class="dropdown-item"><!----> <a href="/categories/Python/" class="nav-link"><i class="undefined"></i>
  Python
</a></li><li class="dropdown-item"><!----> <a href="/categories/Frontend/" class="nav-link"><i class="undefined"></i>
  Frontend
</a></li><li class="dropdown-item"><!----> <a href="/categories/Grammar/" class="nav-link"><i class="undefined"></i>
  Grammar
</a></li><li class="dropdown-item"><!----> <a href="/categories/Networks/" class="nav-link"><i class="undefined"></i>
  Networks
</a></li><li class="dropdown-item"><!----> <a href="/categories/Others/" class="nav-link"><i class="undefined"></i>
  Others
</a></li><li class="dropdown-item"><!----> <a href="/categories/Projects/" class="nav-link"><i class="undefined"></i>
  Projects
</a></li><li class="dropdown-item"><!----> <a href="/categories/Research/" class="nav-link"><i class="undefined"></i>
  Research
</a></li><li class="dropdown-item"><!----> <a href="/categories/Tools/" class="nav-link"><i class="undefined"></i>
  Tools
</a></li></ul></div></div><div class="nav-item"><a href="/tag/" class="nav-link"><i class="iconfont reco-tag"></i>
  Tag
</a></div><div class="nav-item"><a href="/timeline/" class="nav-link"><i class="iconfont reco-date"></i>
  TimeLine
</a></div><div class="nav-item"><div class="dropdown-wrapper"><a class="dropdown-title"><span class="title"><i class="iconfont reco-message"></i>
      Contact
    </span> <span class="arrow right"></span></a> <ul class="nav-dropdown" style="display:none;"><li class="dropdown-item"><!----> <a href="mailto:mail@weigao.cc" class="nav-link external"><i class="iconfont reco-mail"></i>
  Email
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li><li class="dropdown-item"><!----> <a href="https://github.com/chenweigao" target="_blank" rel="noopener noreferrer" class="nav-link external"><i class="iconfont reco-github"></i>
  GitHub
  <span><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" focusable="false" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg> <span class="sr-only">(opens new window)</span></span></a></li></ul></div></div> <!----></nav> <!----> </aside> <div class="password-shadow password-wrapper-in" style="display:none;" data-v-4e82dffc data-v-1156296a><h3 class="title" data-v-4e82dffc data-v-4e82dffc>TensorFlow 入门</h3> <!----> <label id="box" class="inputBox" data-v-4e82dffc data-v-4e82dffc><input type="password" value="" data-v-4e82dffc> <span data-v-4e82dffc>Konck! Knock!</span> <button data-v-4e82dffc>OK</button></label> <div class="footer" data-v-4e82dffc data-v-4e82dffc><span data-v-4e82dffc><i class="iconfont reco-theme" data-v-4e82dffc></i> <a target="blank" href="https://vuepress-theme-reco.recoluan.com" data-v-4e82dffc>vuePress-theme-reco</a></span> <span data-v-4e82dffc><i class="iconfont reco-copyright" data-v-4e82dffc></i> <a data-v-4e82dffc><span data-v-4e82dffc>weigaochen</span>
            
          <span data-v-4e82dffc>2017 - </span>
          2022
        </a></span></div></div> <div data-v-1156296a><main class="page" style="padding-right:0;"><section><div class="page-title"><h1 class="title">TensorFlow 入门</h1> <div data-v-1ff7123e><i class="iconfont reco-account" data-v-1ff7123e><span data-v-1ff7123e>weigaochen</span></i> <i class="iconfont reco-date" data-v-1ff7123e><span data-v-1ff7123e>2017/12/10</span></i> <!----> <i class="tags iconfont reco-tag" data-v-1ff7123e><span class="tag-item" data-v-1ff7123e>paper</span><span class="tag-item" data-v-1ff7123e>CV</span><span class="tag-item" data-v-1ff7123e>deeplearning</span></i></div></div> <div class="theme-reco-content content__default"><p>Tensorflow 中一些简单但是容易忘记的：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf
a <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span> <span class="token comment">#用来表示矩阵的乘法操作</span>

weight <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev <span class="token operator">=</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">)</span> 

bias <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token comment">#偏置项</span>
</code></pre></div><p>tf.Variable 为初始化变量的操作，tf.random_normal 指定了一个 2*3 的矩阵，元素均值为 0，标准差为 2，并且，符合正态分布，其他的可以参考 tensorflow 随机数生成函数</p> <p>接下来这段代码实现神经网络的<strong>前向传播</strong>过程</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
w2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev <span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>seed<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>constant<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span><span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>

a <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>w2<span class="token punctuation">)</span>

sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>

sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">.</span>initializer<span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w2<span class="token punctuation">.</span>initializer<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>y<span class="token punctuation">)</span><span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre></div><p><strong>关于 placeholder</strong>
 一般而言，我们需要使用常量：</p> <p><code>x = tf.constant([[0.7,0.9]])</code></p> <p>但是这样明显加大了 tensorflow 的计算量，所以引入了 placeholder，这时候我们只需要将数据传入计算图，下面是一个例子：</p> <p><code>x = tf.placeholder(tf.float32,shape = (1,2), name = &quot;input&quot;)</code></p> <p>其中的 shape 属性可以不指定，因为数据的维度信息可以根据提供的数据推导得出，但是确定的维度的给出可以降低出错的概论。下面的代码为 placeholder 实现前向传播算法：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf

w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">3</span><span class="token punctuation">]</span><span class="token punctuation">,</span> stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
w2 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">3</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name <span class="token operator">=</span> <span class="token string">&quot;input&quot;</span><span class="token punctuation">)</span>
a <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>a<span class="token punctuation">,</span>w2<span class="token punctuation">)</span>

sess <span class="token operator">=</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span>
init_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_op<span class="token punctuation">)</span>

<span class="token comment"># print(sess.run(y))</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>y<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token number">0.7</span><span class="token punctuation">,</span><span class="token number">0.9</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>需要注意的是被注释的那行代码 <code># print(sess.run(y))</code> ，如果运行的话，解释器会报告一个错误，这是因为我们需要提供一个 feed_dict 来指定 x 的取值。
如果我们需要多个样例的传播结果，只需要：</p> <p><code>x = tf.placeholder(tf.float32,shape=(3,2),name=&quot;input&quot;)</code>  #3 个</p> <p>然后给出三组数据即可：</p> <p><code>sess.run(y,feed_dict={x:[[0.7,0.9],[0.1,0.4],[0.5,0.8]]})</code></p> <p>而后我们定义 loss 函数来刻画预测值和真实值之间的差距，然后通过反向传播算法来调整神经网络的取值从而缩小差距</p> <div class="language-python extra-class"><pre class="language-python"><code>cross_entropy <span class="token operator">=</span> <span class="token operator">-</span>tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>y_ <span class="token operator">*</span> tf<span class="token punctuation">.</span>log<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>clip_by_value<span class="token punctuation">(</span>y<span class="token punctuation">,</span><span class="token number">1e-10</span><span class="token punctuation">,</span><span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">)</span>
</code></pre></div><p>cross_entropy 定义了真实值和预测值之间的<em>交叉熵</em>。
具体而言，交叉熵刚开始的意义是刻画了两个概论分布之间的距离，是分类问题中使用比较广的一种损失函数。在代码中的含义就是 y` 表示正确结果，y 代表预测结果，并且将张量中的数值限制在 1E-10~1.0 之间，以避免一些运算错误
如果与 softmax 一起使用的话，tensorflow 对这两个功能进行了统一封装，调用</p> <p><code>cross_entropy=tf.nn.softmax_cross_entropy_with_logits(y,y_)</code></p> <p>下面是训练过程开始的代码：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    init_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_op<span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w2<span class="token punctuation">)</span><span class="token punctuation">)</span>

    STEPS <span class="token operator">=</span> <span class="token number">5000</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>STEPS<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start <span class="token operator">=</span> <span class="token punctuation">(</span>i <span class="token operator">*</span> batch_size<span class="token punctuation">)</span> <span class="token operator">%</span> dataset_size
        end <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>start <span class="token operator">+</span> batch_size<span class="token punctuation">,</span> dataset_size<span class="token punctuation">)</span>

        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step<span class="token punctuation">,</span> feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span> X<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">,</span> y_<span class="token punctuation">:</span> Y<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">1000</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            total_cross_entropy <span class="token operator">=</span> sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>cross_entropy<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span>X<span class="token punctuation">,</span>y_<span class="token punctuation">:</span>Y<span class="token punctuation">}</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">&quot;After %d training steps,cross entropy is %g&quot;</span><span class="token operator">%</span><span class="token punctuation">(</span>i<span class="token punctuation">,</span>total_cross_entropy<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w2<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><p>训练循环了 5000 次，可以观察到交叉熵的值是越来越小的，这表明预测的结果和真实值的差距越来越小
最后的两行输出表示训练之后神经网络的值</p> <p>** 总结一下，训练神经网络的过程可以分为以下三个步骤：</p> <ul><li>定义网络的结构和前向传播的输出</li> <li>定义损失函数和选择反向传播优化的算法</li> <li>生成会话并且在训练数据上反复运行反向传播优化算法 **</li></ul> <p>有的时候需要自定义损失函数：</p> <div class="language-python extra-class"><pre class="language-python"><code><span class="token keyword">import</span> tensorflow <span class="token keyword">as</span> tf 
<span class="token keyword">from</span> numpy<span class="token punctuation">.</span>random <span class="token keyword">import</span> RandomState

batch_size <span class="token operator">=</span> <span class="token number">8</span>

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name <span class="token operator">=</span> <span class="token string">'x-input'</span><span class="token punctuation">)</span>
y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>float32<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token boolean">None</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>name <span class="token operator">=</span> <span class="token string">'y-input'</span><span class="token punctuation">)</span>

w1 <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>random_normal<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">2</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span>stddev<span class="token operator">=</span><span class="token number">1.0</span><span class="token punctuation">,</span>seed <span class="token operator">=</span> <span class="token number">1.0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
y <span class="token operator">=</span> tf<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>x<span class="token punctuation">,</span>w1<span class="token punctuation">)</span>

loss_less <span class="token operator">=</span> <span class="token number">10</span>
loss_more <span class="token operator">=</span> <span class="token number">1</span>
loss <span class="token operator">=</span> tf<span class="token punctuation">.</span>reduce_mean<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>where<span class="token punctuation">(</span>tf<span class="token punctuation">.</span>greater<span class="token punctuation">(</span>y<span class="token punctuation">,</span>y_<span class="token punctuation">)</span><span class="token punctuation">,</span><span class="token punctuation">(</span>y<span class="token operator">-</span>y_<span class="token punctuation">)</span><span class="token operator">*</span>loss_more<span class="token punctuation">,</span><span class="token punctuation">(</span>y_<span class="token operator">-</span>y<span class="token punctuation">)</span><span class="token operator">*</span>loss_less<span class="token punctuation">)</span><span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token operator">=</span><span class="token number">0.001</span><span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

rdm <span class="token operator">=</span> RandomState<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span>
dataset_size <span class="token operator">=</span> <span class="token number">128</span>
X <span class="token operator">=</span> rdm<span class="token punctuation">.</span>rand<span class="token punctuation">(</span>dataset_size<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span>
Y <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">[</span>x1<span class="token operator">+</span>x2<span class="token operator">+</span>rdm<span class="token punctuation">.</span>rand<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token operator">/</span><span class="token number">10.0</span><span class="token operator">-</span><span class="token number">0.05</span><span class="token punctuation">]</span> <span class="token keyword">for</span> <span class="token punctuation">(</span>x1<span class="token punctuation">,</span>x2<span class="token punctuation">)</span> <span class="token keyword">in</span> X<span class="token punctuation">]</span>

<span class="token keyword">with</span> tf<span class="token punctuation">.</span>Session<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">as</span> sess<span class="token punctuation">:</span>
    init_op <span class="token operator">=</span> tf<span class="token punctuation">.</span>global_variables_initializer<span class="token punctuation">(</span><span class="token punctuation">)</span>
    sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>init_op<span class="token punctuation">)</span>
    Steps <span class="token operator">=</span> <span class="token number">5000</span>
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>Steps<span class="token punctuation">)</span><span class="token punctuation">:</span>
        start <span class="token operator">=</span> <span class="token punctuation">(</span>i<span class="token operator">*</span>batch_size<span class="token punctuation">)</span> <span class="token operator">%</span> dataset_size
        end <span class="token operator">=</span> <span class="token builtin">min</span><span class="token punctuation">(</span>start<span class="token operator">+</span>batch_size<span class="token punctuation">,</span>dataset_size<span class="token punctuation">)</span>
        sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step<span class="token punctuation">,</span>feed_dict<span class="token operator">=</span><span class="token punctuation">{</span>x<span class="token punctuation">:</span>X<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span> <span class="token punctuation">,</span> y_<span class="token punctuation">:</span>Y<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span><span class="token punctuation">}</span><span class="token punctuation">)</span>
        <span class="token keyword">print</span><span class="token punctuation">(</span>sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>w1<span class="token punctuation">)</span><span class="token punctuation">)</span>

</code></pre></div><p>以上自定义了一个损失函数，实际值和预测值之间存在的差值分配不用的系数，我们也可以使用均方误差 (MSE)：</p> <p><code>loss = tf.reduce_mean(tf.square(y_-y))</code></p> <p>通过比较输出的结果可以看出，不同的损失函数会对模型产生重要影响。</p> <p>在优化参数的时候，梯度下降法是最常用的神经网络优化算法，具体而言，对于一个优化算法而言，第一步随机产生一个参数的初始值，然后通过梯度和学习率来更新参数的取值。
梯度下降算法的两个缺陷：第一是可能得到局部最优的结果，第二是计算时间太长，因为要计算所有训练数据的损失函数是非常耗时间的，所以就可以使用随机梯度下降算法，具体而言，就是在每一轮的迭代中，随机优化某一条训练数据上的损失函数，但是随机梯度下降法有的时候甚至无法达到局部最优，所以一般采用<strong>每次计算一小部分训练数据的损失函数</strong>的方法，这一小部分数据称为一个 batch。</p> <p>对于 learning_rate，常用的是指数衰减法</p> <div class="language-python extra-class"><pre class="language-python"><code>global_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>Variable<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>
learning_rate <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>exponential_decay<span class="token punctuation">(</span><span class="token number">0.001</span><span class="token punctuation">,</span>global_step<span class="token punctuation">,</span> <span class="token number">100</span> <span class="token punctuation">,</span> <span class="token number">0.96</span> <span class="token punctuation">,</span>staircase<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>
</code></pre></div><p>dacay_steps 代表了完整的使用一遍训练数据所需要的迭代轮数（总训练样本数除以每一个 batch 的训练样本数），staircase 的值为 True 时，global_step/decay_steps 会被转化成整数。上面各个参数的含义是每训练 100 轮后学习率乘以 0.96。经验有助于设置好学习率、衰减系数和衰减速度。</p> <div class="language-python extra-class"><pre class="language-python"><code>batch_size <span class="token operator">=</span> n

x <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>dtype<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span>
y_ <span class="token operator">=</span> tf<span class="token punctuation">.</span>placeholder<span class="token punctuation">(</span>dtype<span class="token punctuation">,</span>shape <span class="token operator">=</span> <span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span> name<span class="token punctuation">)</span>

loss <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span>
train_step <span class="token operator">=</span> tf<span class="token punctuation">.</span>train<span class="token punctuation">.</span>AdamOptimizer<span class="token punctuation">(</span>learning_rate<span class="token punctuation">)</span><span class="token punctuation">.</span>minimize<span class="token punctuation">(</span>loss<span class="token punctuation">)</span>

<span class="token keyword">with</span> <span class="token punctuation">.</span><span class="token punctuation">.</span> <span class="token punctuation">:</span>
	<span class="token keyword">for</span> _ <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>STEPS<span class="token punctuation">)</span><span class="token punctuation">:</span>
		current_X<span class="token punctuation">,</span>surrent_Y <span class="token operator">=</span> <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
		sess<span class="token punctuation">.</span>run<span class="token punctuation">(</span>train_step<span class="token punctuation">,</span>feed_sict <span class="token operator">=</span> <span class="token punctuation">{</span>x<span class="token punctuation">:</span>current_X<span class="token punctuation">,</span>y_<span class="token punctuation">:</span>current_Y<span class="token punctuation">}</span><span class="token punctuation">)</span>
</code></pre></div><p>以上代码概括了一般神经网络的训练大致遵循的过程。</p></div></section> <footer class="page-edit"><!----> <div class="last-updated"><span class="prefix">更新时间: </span> <span class="time">2022年2月7日星期一 20:45</span></div></footer> <!----> <div class="comments-wrapper"><!----></div> <ul class="side-bar sub-sidebar-wrapper" style="width:0;" data-v-70334359></ul></main> <!----></div></div></div></div><div class="global-ui"><div class="back-to-ceiling" style="right:1rem;bottom:6rem;width:2.5rem;height:2.5rem;border-radius:.25rem;line-height:2.5rem;display:none;" data-v-c6073ba8 data-v-c6073ba8><svg t="1574745035067" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="5404" class="icon" data-v-c6073ba8><path d="M526.60727968 10.90185116a27.675 27.675 0 0 0-29.21455937 0c-131.36607665 82.28402758-218.69155461 228.01873535-218.69155402 394.07834331a462.20625001 462.20625001 0 0 0 5.36959153 69.94390903c1.00431239 6.55289093-0.34802892 13.13561351-3.76865779 18.80351572-32.63518765 54.11355614-51.75690182 118.55860487-51.7569018 187.94566865a371.06718723 371.06718723 0 0 0 11.50484808 91.98906777c6.53300375 25.50556257 41.68394495 28.14064038 52.69160883 4.22606766 17.37162448-37.73630017 42.14135425-72.50938081 72.80769204-103.21549295 2.18761121 3.04276886 4.15646224 6.24463696 6.40373557 9.22774369a1871.4375 1871.4375 0 0 0 140.04691725 5.34970492 1866.36093723 1866.36093723 0 0 0 140.04691723-5.34970492c2.24727335-2.98310674 4.21612437-6.18497483 6.3937923-9.2178004 30.66633723 30.70611158 55.4360664 65.4791928 72.80769147 103.21549355 11.00766384 23.91457269 46.15860503 21.27949489 52.69160879-4.22606768a371.15156223 371.15156223 0 0 0 11.514792-91.99901164c0-69.36717486-19.13165746-133.82216804-51.75690182-187.92578088-3.42062944-5.66790279-4.76302748-12.26056868-3.76865837-18.80351632a462.20625001 462.20625001 0 0 0 5.36959269-69.943909c-0.00994388-166.08943902-87.32547796-311.81420293-218.6915546-394.09823051zM605.93803103 357.87693858a93.93749974 93.93749974 0 1 1-187.89594924 6.1e-7 93.93749974 93.93749974 0 0 1 187.89594924-6.1e-7z" p-id="5405" data-v-c6073ba8></path><path d="M429.50777625 765.63860547C429.50777625 803.39355007 466.44236686 1000.39046097 512.00932183 1000.39046097c45.56695499 0 82.4922232-197.00623328 82.5015456-234.7518555 0-37.75494459-36.9345906-68.35043303-82.4922232-68.34111062-45.57627738-0.00932239-82.52019037 30.59548842-82.51086798 68.34111062z" p-id="5406" data-v-c6073ba8></path></svg></div><!----></div></div>
    <script src="/assets/js/app.ff413545.js" defer></script><script src="/assets/js/3.a9798fbe.js" defer></script><script src="/assets/js/1.76b01c69.js" defer></script><script src="/assets/js/89.8d98fea8.js" defer></script><script src="/assets/js/9.0cdfd736.js" defer></script>
  </body>
</html>
